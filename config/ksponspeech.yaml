model:
  encoder:
    model_dim: 1024
    ffn_dim: 2048
    layers: 6
    heads: 8
    vocab_size: ???

  decoder:
    model_dim: 512
    ffn_dim: 2048
    layers: 6
    heads: 8
    vocab_size: ???

train:
  optim: adam
  loss: rrn-t
  device: cuda
  lr: 0.0001
  batch_size: 16
  epochs: 50
  save_epoch: 1
  
feature:
  spec: 
    sample_rate: 16000
    n_mels: 80
    n_fft: 512
    hop_length: 256
    win_length: 512
    normalized: True
  augment:
    spec_augment: True
    time_shifting: False
    noise_injecting: False
  