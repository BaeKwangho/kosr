model:
  encoder:
    model_dim: 256
    ffn_dim: 2048
    layers: 16
    heads: 4
    vocab_size: ???

  decoder:
    model_dim: 640
    ffn_dim: 2048
    layers: 1
    heads: 8
    vocab_size: ???

optimizer:
  optim: adam
  loss: rrn-t
  lr: 0.0001
  peak_lr: 5e-2
  min_lr: 1e-6
  ramp_up: 16000
  exp_decay: 800000
  weight_decay: 2e-6
  scheduler: exp

train:
  device: cuda
  batch_size: 16
  epochs: 50
  save_epoch: 1
  
feature:
  spec: 
    sample_rate: 16000
    n_mels: 80
    n_fft: 512
    hop_length: 256
    win_length: 512
    normalized: True
  augment:
    spec_augment: True
    time_shifting: False
    noise_injecting: False
  